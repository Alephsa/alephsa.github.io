{"pages":[{"url":"/pages/porque-alephsa.html","text":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Sed mollis ultrices risus, eget dignissim ante tristique pulvinar. In hac habitasse platea dictumst. Morbi nec urna non sapien convallis commodo. Vivamus non feugiat sem. Duis et cursus lorem. Suspendisse venenatis, dolor in venenatis semper, justo odio blandit lacus, id lacinia magna neque eu dolor. Ut eu libero vitae quam dapibus malesuada. Integer vitae ex nec erat eleifend ultrices. Integer sollicitudin arcu a eleifend rhoncus. Suspendisse felis felis, ornare eu metus dictum, semper molestie turpis. Nunc et congue dolor. Pellentesque rutrum consequat odio, non efficitur arcu bibendum sit amet. Aliquam quis lectus sit amet nisl porta gravida. Maecenas rutrum ante in ante consequat, vel vestibulum nunc sodales. In vulputate tristique vehicula. Mauris in sollicitudin ante. Aliquam mollis facilisis est, non aliquet orci mollis et. Fusce volutpat eros ut malesuada interdum. Quisque vel massa ex. Pellentesque et aliquet ex. Nulla sodales at est ac porttitor. Donec blandit tellus nulla. Aliquam rhoncus velit a semper tincidunt. Maecenas feugiat lacus nec nisi fringilla tempor. In hac habitasse platea dictumst. Nunc justo tortor, ornare eget est at, egestas tempus purus. Sed leo sem, scelerisque non congue eu, interdum sed eros. Morbi at varius lorem, et pharetra elit. Integer imperdiet ante elit, sit amet aliquet elit feugiat quis. Aliquam laoreet cursus ultrices. Mauris est eros, convallis a arcu eu, lacinia rhoncus sem. .","tags":"Alephsa","title":"Alephsa?"},{"url":"/pages/ada.html","text":"contenido de ADA","tags":"Alephsa","title":"Análisis de datos"},{"url":"/pages/community.html","text":"contenido de community","tags":"Alephsa","title":"Comunidades"},{"url":"/pages/infocracia.html","text":"contenido de infocracia","tags":"Alephsa","title":"Infocracia"},{"url":"/pages/team.html","text":"contenido de equipo","tags":"Alephsa","title":"Equipo"},{"url":"/2015/06/openrefine-split.html","text":"En muchos proyectos de Alephsa nos encontramos con dataset que contienen datos subcodificados o necesitamos dividir un dato para mejorar la cantidad de información disponible, en nuestro ejemplo para responder un par de preguntas interesantes ( ¿Como se distribuye en el tiempo la firma de los contratos? y ¿Cómo se distribuyen geográficamente los contratos? ) necesitamos operar sobre un par de columnas de nuestro dataset . Separar automáticamente una columna La columna deptomunicejecucion contine los datos de los departamentos y municipios separados por un guión, para separarlos (columna->Edit column->Split into several columns...) en dos columnas usamos las opciones disponibles y luego renombramos las columnas como departmento y municipio (columna->Edit column->Rename column).","tags":"Tools","title":"Separar datos en Openrefine"},{"url":"/2015/06/openrefine-duplicates.html","text":"Un asunto importante en la limpieza de datos es poder encontrar los registros duplicados, muchas veces al sumar fuentes de datos heterogeneas es posible que se encuentren los mismos datos y eso desvie el análisis de manera inconveniente, en OpenRefine es muy sencillo encontrar y eliminarlos. Normalizar los datos Con una simple inspección de la primer página de registros notamos que las columnas contienen datos en mayúsculas/minúsculas para normalizarlas usamos las transformaciones comunes de celdas (clic en la columna->Edit cells->Common transforms->To uppercase) en todas las columnas de tipo texto. Ahora bien, es posible que haya datos muy similares por columna pero no iguales, para encontrarlos usamos las funciones integradas de OpenRefine para hacer clusters a partir de funciones de comparación de cadenas de texto 1 como keycollision o Levenshtein : La idea es que se usa un algoritmo para encontrar valores que posiblemente sean iguales pero por alguna razón no aparecen asi en los datos, en nuestro caso con Keycollision / fingerprint encontramos más de 14000 posibles clusters, sin embargo no siempre son acertadas las propuestas asi que vamos a refinar la busqueda usando el panel derecho en la segunda fila para mostrar únicamente los clusters encontrados con más de 100 registros, para obtener 71 posibles clusters , revisamos cada uno y seleccionamos para normalizar los que tengan más sentido (S.N. transformarlo en N/A, '-' transformarlo en 'N/A', etc): Este procedimiento podemos efectuarlo de forma iterativa hasta lograr una normalización aceptable de los datos en la columna, del mismo modo podemos hacerlo sobre las otras columnas para dejar los clusters mas apropiados y luego encontrar los duplicados. (Aquí es donde la mayor parte del tiempo se invierte). Otra forma de filtrar los datos es buscar las agrupaciones que no corresponden con su tipo de datos, por ejemplo, en la columna valorcontrato podemos aplicar un Facet de tipo numerico para arreglar los registros que no se encuentran con el formato apropiado. También podemos convertir la columna fechafirmacontrato en un tipo de datos Date (clic en columna->Edit cells->Common transforms->To date) para luego aplicar un facet de tipo timeline para detectar los que debemos modificar. Para acelerar nuestro ejemplo optamos por eliminar dichos registros ( no es la práctica recomendada ), con lo cual obtenemos un dataset de 625947 registros a los cuales vamos a quitarles los duplicados. Encontrar los duplicados Los duplicados pueden referirse a valores únicos de una columna, por ejemplo buscar los id únicos de un dataset , estamos tentados a aplicar la solución que se describe en la wiki de OpenRefine para eliminar los duplicados: Order de manera permanente los datos de la columna por la cual queremos eliminar los duplicados Hacer un blank down (clic en la columna->Edit cells->Blank down) para dejar como nulos los valores repetidos en la columna Agrupar con un Facet nulo (clic en la columna->Facet-Customized facets->Facet by blank) y seleccionar los nulos en el panel izquierdo Eliminar las filas Sin embargo, al conocer el dominio del problema, sabemos que pueden hacerse múltiples contratos para varios proveedores en el mismo proceso de contratación, así que para nuestro ejemplo vamos a buscar los registros que comparten: numerodecontrato numerodeproceso detalleobjeto razonsocialcontratista Para ello seleccionamos en cada columna un Facet de tipo duplicate (clic en la columna->Facet-Customized facets->Duplicates facet) y en la panel izquierdo hacemos clic en true para cada uno de los grupos. De esa manera podemos borrar los registros de los contratos completamente duplicados, después de lo cual tenemos 589866 registros para responder algunas preguntas. Entre otras, ¿Como se distribuye en el tiempo la firma de los contratos?, ¿Cómo se distribuyen geográficamente los contratos? para responder estas preguntas debemos separar la columna deptomunicejecucion y fechafirmacontrato , lo cual veremos en la próxima entrega de la serie. Para conocer más se puede consultar el proyecto Simmetrics en Github ↩","tags":"Tools","title":"Duplicados en Openrefine"},{"url":"/2015/06/openrefine-filters.html","text":"En nuestro post anterior generamos un proyecto en OpenRefine que debería contener 628118 registros, sin embargo, nuestro dataset cargado muestra 628111, están todos los que son? son todos los que están?, bueno con ayuda de OpenRefine en Alephsa hemos podido responder estas preguntas en varios proyectos de manera exitosa. Encontrar los faltantes Conocer el dominio sobre el cual nos movemos nos permite probar de formular de manera intuitiva algunas alternativas para encontrar los registros faltantes, en este caso sabemos que el numero de contrato es una dato sine qua non puede existir un registro en el dataset que estamos trabajando, asi que nuestra primera aproximación es buscar los datos con valores nulos o blancos en la columna numerocontrato , para ello hacemos clic en el triangulo al lado del nombre y seleccionamos un Facet (agrupación) para encontrar valores nulos: Ahora bien, en el panel lateral izquierdo notamos que hay 13 filas con valor nulo, hacemos clic sobre true para seleccionarlos y veremos que hay filas sin valor, como no conocemos el valor exacto para esos registros vamos a copiar el valor de la columna numero de proceso , para ello podemos editar el valor de cada celda (con el puntero señalamos la celda que queremos editar) con un dato estandar \"N/A\", luego retiramos la agrupación del panel izquierdo, ordenamos la columna numerocontrato alfabeticamente (Sort...) y finalmente hacemos el orden permanente: Y notaremos que ahora tenemos 628124 registros, porqué tantos? Quitar los sobrantes Al crear el proyecto los titulos de las columnas fueron tomados del archivo agrupado que generamos a partir de la suma de los archivos individuales, nuevamente, usando nuestra intuición suponemos que cada archivo que descargamos contiene las mismas cabeceras y para probar nuestra sospecha agregamos un filtro de tipo texto y buscamos el nombre de la columna sobre el cual lo agregamos: En los filtros podemos usar expresiones regulares, los resultados nos muestran seis registros con los datos de nombres de las columnas, vamos a borrar estas filas haciendo clic en la columna llamada All y seleccionando \"Edit rows->delete all matching rows\", asi obtenemos los 628118 registros que buscabamos!. John McClane: Stop all the goddamn yellin'! I know what I'm doing. Y ahora? Ahora vamos a buscar los registros duplicados, a separar las columna departamentomunicipio en dos y algunas otras cosas interesantes para poder hacer una descripción medianamente acertada de los datos. En los siguientes artículos de la serie hay más información.","tags":"Tools","title":"Filtros y grupos en Openrefine"},{"url":"/2015/06/openrefine-install.html","text":"En Alephsa manejamos datasets 1 muy variados, y las labores de ingenieria de datos además de gustarnos nos permite probar herramientas muy variadas, de hecho es bien conocido que la mayor parte del trabajo en data science actualmente tiene que ver con la ingeniería de datos, es decir a labores de búsqueda, descarga y limpieza de datos. Openrefine es una herramienta que provee un servidor para realizar este tipo de tareas con un cliente web muy sencillo de manejar, incluye utilidades comunes para el tratamiento de datos, un lenguaje de expresiones propio ( GREL ) o usar Python ( Jython 2.5.1 ) como lenguaje 2 . En esta serie de post trabajaremos sobre Linux pero las instrucciones son fácilmente adaptables a otros sistemas operativos 3 . Primeros pasos La wiki de OpenRefine tiene instrucciones muy claras sobre la descarga y ejecución en Linux, Win2 y MacOS. Sin embargo me gustaría agregar que es buena idea agregar más memoria a la ejecución del servidor si se quiere trabajar comodamente con datasets de mas de algunas decenas de miles de datos. Para ello la wiki contiene instrucciones claras por plataforma. Dataset de ejemplo Existen muchos conjuntos de datos disponibles en la red, para nuestros ejercicios vamos a usar los disponibles en el Catalogo de datos abiertos del estado Colombiano , más específicamente los \" Contratos públicos activos publicados en el secop \" (461268 registros) y el \" Histórico de los contratos públicos publicados en el secop \" (166850 registros) que nos deberian permitir trabajar sobre una base de 628118 filas con las siguientes columnas: numerocontrato numeroproceso tipoproceso estadocontrato tipocontrato nombreentidad detalleobjeto razonsocialcontratista deptomunicejecucion valorcontrato fechafirmacontrato fechaliquidacion fechaterminacionanticipada Sobre los cuales vamos a hacer algunas tareas comunes para poder hacer un analisis preliminar. Agregando los datos Cada uno de los dataset consiste en varios archivos separados por comas (CSV) que debemos concatenar antes de cargarlos en OpenRefine. Para ello desde una terminal nos situamos en el directorio donde tenemos los archivos y ejecutamos: > cd /home/usuario/directorio_donde_estan_los_archivos > cat Ministerio_de_tecnologias_de_informacion_y_las_comunicaciones.contratoshistoricos* > mtic.contratos.historicos.csv > cat Ministerio_de_tecnologias_de_informacion_y_las_comunicaciones.contratosactivos* mtic.contratos.activos.csv > cat mtic.contratos.* > mtic.contratos.csv estos comandos agruparan en tres archivos todos los que descargamos previamente: mtic.contratos.activos.csv mtic.contratos.historicos.csv mtic.contratos.csv : Suma de los anteriores y desde OpenRefine hacemos un nuevo proyecto con el archivo mtic.contratos.csv : Una vez generado el proyecto lo primero que notamos es que el numero de registros no coincide (628111 vs 628118 esperados), porque? cómo lo arreglamos?, para resolver éstas y otras dudas (además de generar nuevas dudas), por favor, continúe con nuestro siguiente post. Un saludo. conjuntos de datos ↩ Estaria bueno incluir la nueva version 2.7 de Jython para tener mayor compatibilidad ↩ Aunque deberia considerar probar Linux, es libre y tiene muchas otras ventajas ↩","tags":"Tools","title":"Openrefine"},{"url":"/2015/06/r-en-ubuntu.html","text":"En el curso de herramientas para data science 1 que estoy tomando via Coursera tienen videos de instalación del entorno de trabajo para R en plataformas MAC y Win2, sin embargo no hay una guía para Linux (Ubuntu). R R se encuentra actualmente en su versión 3.2.1 (18/06/2015) pero Ubuntu 14.04 trae en sus repositorios la version 3.0.1, asi que vamos a usar el repositorio actualizado por Michael Rutter , para desde una terminal: sudo add-apt-repository ppa:marutter/rrutter sudo apt-get update sudo apt-get install r-base Consume unos 101Mb de espacio y puede verificarse la versión instalada usando el siguiente comando desde la terminal: R > version que nos debe arrojar una respuesta como: platform x86_64-pc-linux-gnu arch x86_64 os linux-gnu system x86_64, linux-gnu status major 3 minor 2.1 year 2015 month 06 day 18 svn rev 68531 language R version.string R version 3.2.1 (2015-06-18) nickname World-Famous Astronaut > q() Save workspace image? [y/n/c]: n R Studio RStudio es un IDE basado en QT para trabajar sobre R, para instalarlo basta con tener descomprimir el tar.gz descargado del sitio web y ejecutar bin/rstudio o usar uno de los instaladores provistos por plataforma. Imagen de Cabecera: David Goehring The Data Scientist's Toolbox ↩","tags":"Tools","title":"R en ubuntu"},{"url":"/2015/06/wordpress-to-pelican.html","text":"http://docs.getpelican.com/en/3.1.1/importer.html https://github.com/dreikanter/wp2md -> mejor Instalación Virtualenv Importar contenido Plantillas Plugins Imagen de Cabecera: Chad Sparkes","tags":"Blogging","title":"Desde wordpress a pelican"}]}